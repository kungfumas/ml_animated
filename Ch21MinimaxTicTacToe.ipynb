{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "653089c9",
   "metadata": {},
   "source": [
    "# Chapter 21: Minimax Game Strategies: Solve Tic Tac Toe\n",
    "\n",
    "In this chapter, youâ€™ll learn how minimax algorithms work. You'll use it to play the Tic Tac Toe game that we developed in Chapter 11. The algorithm exhausts all possibilities in the Tic Tac Toe game. The minimax agent plays perfectly: no strategy can beat it. \n",
    "\n",
    "We then deploy the game to the online platform replit.com, where you can play against the minimax algorithm. Even if you move first, the best you can do is to force a tie-game. You can never beat the minimax agent (it's mathematically proven!). \n",
    "\n",
    "You can play the game live here\n",
    "\n",
    "https://replit.com/@MarkLiu11/Tic-Tac-Toe-Minimax-Solver?v=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b25bf6",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{Create a subfolder for files in Chapter 21}}$<br>\n",
    "***\n",
    "We'll put all files in Chapter 21 in a subfolder /files/ch21. Run the code in the cell below to create the subfolder.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "117477d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"files/ch21\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282ad876",
   "metadata": {},
   "source": [
    "## 1. Introduction to the Minimax Algorithm\n",
    "We'll introduce the minimax algorithm in the section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c437e8",
   "metadata": {},
   "source": [
    "### 1.1. What is the Minimax Algorithm?\n",
    "The minimax algorithm is a decision rule in artificial intelligence and game theory. It's also called MinMax. \n",
    "\n",
    "In a nutshell, the algorithm assumes that: \n",
    " \n",
    "*\tEach player in the game makes the best possible decisions at each step;\n",
    "*\tFurther, each player knows that other players make fully rational decisions as well;\n",
    "*\tEach players knows that other players know that he/she makes the best possible decisions;\n",
    "*   and so on...\n",
    "\n",
    "In a two-player game, each player makes decisions to maximize his/her own expected payoff and to minimize the opponent's payoffs. Hence the name minimax. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d7767",
   "metadata": {},
   "source": [
    "### 1.2. The Minimax Algorithm with Backward Induction\n",
    "The solution in a minimax algorithm is achieved through backward induction. It starts with the terminal state of the game (in Tic Tac Toe, when the game is tied or when one player has won) and finds out the payoffs to each player in that state. In the second to last stage of the game, the player looks one step ahead and makes the best decision for himself/herself, anticipating that the opponent makes the best decision in the previous stage, and so on.\n",
    "\n",
    "Let's use the Tic Tac Toe game as the example. Each game has a maximum of 9 stages. In stage 9 (assuming the game is not over by then), player X has only one choice so no decision is needed. In stage 8, player O looks at the two choices and picks the best one for himself/herself. In stage 7, player X picks the best decision, knowing that player O will pick a choice that minimizes player X's payoff in stage 8, and so on. The reasoning goes all the way back to the very first step when player X makes a decision. \n",
    "\n",
    "Since the total number of possible scenarios in a Tic Tac Toe game is small (less than $3^9=19,683$), the computer program can exhaust all scenarios in a short amount of time and find the best solution for each player in every stage of the game. \n",
    "\n",
    "However, for more complicated games such as Chess and Go, the total number of possible scenarios in a game is astronomical. It's impossible for the minimax algorithm to pick the best move in a reasonable amount of time. We'll discuss how to mitigate this concern in later chapters. One easy mitigating method is to stop searching after a fixed number of stages. For example, you can limit the program to look ahead at most four steps so that the program can recommend a solution in just a few seconds. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db31da9",
   "metadata": {},
   "source": [
    "## 2. Implement the Minimax Algorithm in Tic Tac Toe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7252a608",
   "metadata": {},
   "source": [
    "We'll use the self-made Tic Tac Toe game environment from Chapter 11. Specifically, the module is saved as *TicTacToe_env.py* in the folder *utils* in this GitHub repository. \n",
    "\n",
    "First, let's define a couple of functions that the algorithm will use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ddc025",
   "metadata": {},
   "source": [
    "### 2.1. The minimax_X() Function\n",
    "We'll define a minimax_X() function for the player X. Potentially we can define one function for both players but it's more difficult to explain. There is a tradeoff between coding efficiency and the understandability of the code. So here we choose the latter. \n",
    "\n",
    "The function tells the player X what's the best next move, anticipating that player O will make the best decision in the next stage as well, and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8839e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax_X():\n",
    "    # to speed up, choose 5 as the very first move\n",
    "    if env.occupied[\"X\"]==[]:\n",
    "        return \"5\"\n",
    "    # the above two lines of code are not needed except to save time\n",
    "    wins=[]\n",
    "    ties=[]\n",
    "    losses=[]  \n",
    "    # iterate through all possible next moves\n",
    "    for m in env.validinputs:\n",
    "        # make a hypothetical move and see what happens\n",
    "        env_copy=deepcopy(env)\n",
    "        new_state, reward, done, info = env_copy.step(m) \n",
    "        # If player X wins right away with move m, take it.\n",
    "        if done and reward==1:\n",
    "            return m \n",
    "        # See what's the best response from the opponent\n",
    "        opponent_best=best_outcome(env_copy, reward, done)  \n",
    "        # Opponent's payoff is the opposite of your payoff\n",
    "        my_payoff=-1*opponent_best \n",
    "        if my_payoff==1:\n",
    "            wins.append(m)\n",
    "        elif my_payoff==0:\n",
    "            ties.append(m)\n",
    "        else:\n",
    "            losses.append(m)\n",
    "    # pick winning moves if there is any        \n",
    "    if wins:\n",
    "        return choice(wins)\n",
    "    # otherwise pick tying moves\n",
    "    if ties:\n",
    "        return choice(ties)\n",
    "    return choice(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05110e83",
   "metadata": {},
   "source": [
    "To speed up the game, we choose Cell 5 as the very first move for player X. If we don't do this, the first move takes 10 to 20 seconds. You can try to delete this part of the code and see what happens.\n",
    "\n",
    "If it's not the very first move, player X iterates through all possible next moves. Note that we need to use deepcopy here. In Python, when you make a regular copy of an object, you just create a link to the original object. When you make changes to the copy, the original is changed as well. To avoid this, we need to use deepcopy. Many Python beginners make mistakes on this and couldn't figure out what's wrong with their code.\n",
    "\n",
    "\n",
    "If player X finds a move that allows him/her to win the game right away, player X will stop searching and take the move. Otherwise, player X will see what's the best outcome for player O in the next stage, knowing full well that player O will make the best decision to maximize player O's payoff. Since it's a zero-sum game, payer X's payoff is the opposite of player O's payoff. Player X will then pick winning moves if there is one; otherwise, he/she will pick a typing move; otherwise, player X has no choice but to pick whatever move is left. \n",
    "\n",
    "Here, we use the *best_outcome(env_copy, reward, done)* function to find the best payoff for player O in the next stage. Let's define that function next.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099241b6",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{Deepcopy in Python}}$<br>\n",
    "***\n",
    "In Python, when you make a regular copy of an object, you just create a link to the original object. When you make changes on the copy, the original is changed as well. To avoid this, we need to use deepcopy when we make hypothetical game moves. Many Python beginners make mistakes on this and couldn't figure out what's wrong with their code.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee28a4e",
   "metadata": {},
   "source": [
    "### 2.2. The *best_outcome()* Function \n",
    "Next, we'll define *best_outcome(env, reward, done)* function. This function produces the best possible outcome for the next player in the next stage of the game. Note this function applies to any stage of the game so we don't need to define one for player X and one for player O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a847d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_outcome(env, reward, done):\n",
    "    # if the game has ended after the previous player's move, calculate the payoffs\n",
    "    if done:\n",
    "        # if the previous player won\n",
    "        if reward==1 and env.turn==\"O\":\n",
    "            return 1\n",
    "        if reward==1 and env.turn==\"X\":\n",
    "            return -1\n",
    "        if reward==-1 and env.turn==\"O\":\n",
    "            return -1\n",
    "        if reward==-1 and env.turn==\"X\":\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    # Otherwise, the opponent searches for the best payoff\n",
    "    best = -1\n",
    "    for m in env.validinputs:\n",
    "        env_copy=deepcopy(env)\n",
    "        new_state, reward, done, info = env_copy.step(m)      \n",
    "        opponent_best = best_outcome(env_copy, reward, done)         \n",
    "        my_best = -1*opponent_best \n",
    "        if my_best > best:        \n",
    "            best = my_best\n",
    "    return best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e6bd0a",
   "metadata": {},
   "source": [
    "If the game has ended after the previous player's move, the function calculates the payoff to the next player based on the game outcome. Otherwise, the next player searches for the best action by iterating throug all possible next moves, knowing full well that the opponent takes a fully rational action in the next stage as well.\n",
    "\n",
    "Note here that we have used the *best_outcome()* function in the *best_outcome()* function itself. This creates an infinite loop. The function keeps on searching to the next stage until the game ends. The process exhausts all game scenarios in Tic Tac Toe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0977029b",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{Use A Function in the Function Itself}}$<br>\n",
    "***\n",
    "In Python, you can put a function in the function itself. This creates an infinite loop. The function keeps on searching to the next stage until a certain condition is met. In the case of the best_outcome() function above. The infinite loop stops until the Tie Tac Toe game is finished (that is, a player has won or the game is tied). The process exhausts all game scenarios. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d963a4e3",
   "metadata": {},
   "source": [
    "### 2.3. Play A Game Against the Minimax Algorithm \n",
    "Next, you'll play a game against the minimax algorithm. We'll let the computer move first and you move second. Don't worry, you'll have a chance to move first in the next section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b9c0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter a move in the form of 1 to 9\n",
      "the current state is state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Player X has chosen action=5\n",
      "the current state is state\n",
      "[[0 0 0]\n",
      " [0 1 0]\n",
      " [0 0 0]]\n",
      "Player O, what's your move?\n",
      "4\n",
      "Player O has chosen action=4\n",
      "the current state is state\n",
      "[[ 0  0  0]\n",
      " [-1  1  0]\n",
      " [ 0  0  0]]\n",
      "Player X has chosen action=1\n",
      "the current state is state\n",
      "[[ 0  0  0]\n",
      " [-1  1  0]\n",
      " [ 1  0  0]]\n",
      "Player O, what's your move?\n",
      "9\n",
      "Player O has chosen action=9\n",
      "the current state is state\n",
      "[[ 0  0 -1]\n",
      " [-1  1  0]\n",
      " [ 1  0  0]]\n",
      "Player X has chosen action=2\n",
      "the current state is state\n",
      "[[ 0  0 -1]\n",
      " [-1  1  0]\n",
      " [ 1  1  0]]\n",
      "Player O, what's your move?\n",
      "8\n",
      "Player O has chosen action=8\n",
      "the current state is state\n",
      "[[ 0 -1 -1]\n",
      " [-1  1  0]\n",
      " [ 1  1  0]]\n",
      "Player X has chosen action=3\n",
      "the current state is state\n",
      "[[ 0 -1 -1]\n",
      " [-1  1  0]\n",
      " [ 1  1  1]]\n",
      "Player X has won!\n"
     ]
    }
   ],
   "source": [
    "from utils import TicTacToe_env \n",
    "import time\n",
    "import random\n",
    "from random import choice\n",
    "from copy import deepcopy\n",
    "\n",
    "# Initiate the game environment\n",
    "env=TicTacToe_env.ttt()\n",
    "state=env.reset()   \n",
    "env.render()\n",
    "\n",
    "def best_outcome(env, reward, done):\n",
    "    # if the game has ended after the previous player's move, calculate the payoffs\n",
    "    if done:\n",
    "        # if the previous player won\n",
    "        if reward==1 and env.turn==\"O\":\n",
    "            return 1\n",
    "        if reward==1 and env.turn==\"X\":\n",
    "            return -1\n",
    "        if reward==-1 and env.turn==\"O\":\n",
    "            return -1\n",
    "        if reward==-1 and env.turn==\"X\":\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    # Otherwise, the opponent searches for the best payoff\n",
    "    best = -1\n",
    "    for m in env.validinputs:\n",
    "        env_copy=deepcopy(env)\n",
    "        new_state, reward, done, info = env_copy.step(m)      \n",
    "        opponent_best = best_outcome(env_copy, reward, done)         \n",
    "        my_best = -1*opponent_best \n",
    "        if my_best > best:        \n",
    "            best = my_best\n",
    "    return best\n",
    "\n",
    "def minimax_X():\n",
    "    # to speed up, choose 5 as the very first move\n",
    "    if env.occupied[\"X\"]==[]:\n",
    "        return \"5\"\n",
    "    # the above two lines of code are not needed except to save time\n",
    "    wins=[]\n",
    "    ties=[]\n",
    "    losses=[]  \n",
    "    # iterate through all possible next moves\n",
    "    for m in env.validinputs:\n",
    "        # make a hypothetical move and see what happens\n",
    "        env_copy=deepcopy(env)\n",
    "        new_state, reward, done, info = env_copy.step(m) \n",
    "        # If player X wins right away with move m, take it.\n",
    "        if done and reward==1:\n",
    "            return m \n",
    "        # See what's the best response from the opponent\n",
    "        opponent_best = best_outcome(env_copy, reward, done)  \n",
    "        # Opponent's payoff is the opposite of your payoff\n",
    "        my_payoff = -1*opponent_best \n",
    "        if my_payoff==1:\n",
    "            wins.append(m)\n",
    "        elif my_payoff==0:\n",
    "            ties.append(m)\n",
    "        else:\n",
    "            losses.append(m)\n",
    "    # pick winning moves if there is any        \n",
    "    if wins:\n",
    "        return choice(wins)\n",
    "    # otherwise pick tying moves\n",
    "    if ties:\n",
    "        return choice(ties)\n",
    "    return choice(losses)\n",
    "\n",
    "\n",
    "print(\"enter a move in the form of 1 to 9\")\n",
    "\n",
    "# Play a full game manually\n",
    "while True:\n",
    "    print(f\"the current state is state\\n{state.reshape(3,3)[::-1]}\")    \n",
    "    action = minimax_X()\n",
    "    \n",
    "    print(f\"Player X has chosen action={action}\")    \n",
    "    new_state, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done:\n",
    "        print(f\"the current state is state\\n{new_state.reshape(3,3)[::-1]}\")\n",
    "        if reward==1:\n",
    "            print(f\"Player X has won!\") \n",
    "        else:\n",
    "            print(f\"It's a tie!\") \n",
    "        break\n",
    "    print(f\"the current state is state\\n{new_state.reshape(3,3)[::-1]}\")    \n",
    "    \n",
    "    action = input(\"Player O, what's your move?\\n\")\n",
    "    print(f\"Player O has chosen action={action}\")    \n",
    "    new_new_state, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done:\n",
    "        print(f\"the current state is state\\n{new_new_state.reshape(3,3)[::-1]}\")\n",
    "        print(f\"Player O has won!\") \n",
    "        break\n",
    "    else: \n",
    "        # play next round\n",
    "        state=new_new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2033eed1",
   "metadata": {},
   "source": [
    "The minimax algorithm first occupies Cell 5. I occupied Cell 4. The minimax algorithm then occupies Cell 1, creating a double attack: it can win in either Cell 3 or Cell 8 in the next move. Since I can only stop one of the two attacks, the minimax algorithm has generated a move to guarantee a win. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ece520",
   "metadata": {},
   "source": [
    "### 2.4. Test the Efficacy of the Minimax Algorithm\n",
    "Next, weâ€™ll test how often the Minimax Algorithm wins against the deep-learning game strategy that we developed in Chapter 11. \n",
    "\n",
    "The following script does that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d392cd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of winning games for player X is 6\n",
      "the number of tying games is 94\n",
      "the number of losing games for player X is 0\n"
     ]
    }
   ],
   "source": [
    "from utils.TicTacToe_env import ttt\n",
    "import time\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a deep learning game strategy for player O based on Chapter 11\n",
    "reload = tf.keras.models.load_model('files/ch11/trained_ttt100K.h5')\n",
    "def DL_move_O(board, valids):\n",
    "    # if there is only one valid move, take it\n",
    "    if len(valids)==1:\n",
    "        return valids[0]\n",
    "    # Set the initial value of bestoutcome        \n",
    "    bestoutcome = -1;\n",
    "    bestmove=None    \n",
    "    #go through all possible moves hypothetically to predict outcome\n",
    "    for move in valids:\n",
    "        tooccupy=deepcopy(board).reshape(9,)\n",
    "        tooccupy[int(move)-1]=1\n",
    "        prediction=reload.predict(np.array(tooccupy).reshape(-1, 3,3,1), verbose=0)\n",
    "        win_lose_dif=prediction[0][1]-prediction[0][2]\n",
    "        if win_lose_dif>=bestoutcome:\n",
    "            # Update the bestoutcome\n",
    "            bestoutcome = win_lose_dif\n",
    "            # Update the best move\n",
    "            bestmove = move\n",
    "    return bestmove\n",
    "\n",
    "\n",
    "env=ttt()\n",
    "\n",
    "def test_one_game():\n",
    "    state=env.reset()   \n",
    "    while True:\n",
    "        # the minimax agent moves first\n",
    "        action = minimax_X()   \n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            break \n",
    "        # the deep learning agent moves second\n",
    "        action = DL_move_O(new_state,env.validinputs)   \n",
    "        new_new_state, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "        else: \n",
    "            # play next round\n",
    "            state=new_new_state\n",
    "    return reward\n",
    "\n",
    "#repeat the game 100 times and record all game outcomes\n",
    "results=[]        \n",
    "for x in range(100):\n",
    "    result=test_one_game()\n",
    "    results.append(result)    \n",
    "\n",
    "#print out the number of winning games\n",
    "print(\"the number of winning games for player X is\", results.count(1))\n",
    "\n",
    "#print out the number of tying games\n",
    "print(\"the number of tying games is\", results.count(0))\n",
    "\n",
    "#print out the number of losing games\n",
    "print(\"the number of losing games for player X is\", results.count(-1))                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b8f32",
   "metadata": {},
   "source": [
    "The minimax agent never loses in the 100 games. It tied the game 94 times and won the game 6 time. So the minimax agent is unbeatable. At the same time, the deep learning game strategy we developed in Chapter 11 is also highly effective: agaist a mathematically solved solution, it forced a tie 94 out of 100 times, when playing second."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbe6000",
   "metadata": {},
   "source": [
    "## 3. When the Minimax Agent Moves Second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1417875",
   "metadata": {},
   "source": [
    "Next, we'll see how good the minimax algorithm is when the minimax agent moves second, hence relinquishing the first mover advantage. \n",
    "\n",
    "For that, we need to define a *minimax_O()* function for player O."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7710c0ce",
   "metadata": {},
   "source": [
    "### 3.1. The minimax_O() Function\n",
    "We'll define a minimax_O() function for player O. The function is similar to the minimax_X() function, except that we need to take into account the fact that player O moves second instead of first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b94f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax_O():\n",
    "    # to speed up, choose 1 or 5 as the very first move for player O\n",
    "    if env.occupied[\"O\"]==[]:\n",
    "        if env.occupied[\"X\"]==[\"5\"]:\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"5\"\n",
    "    # the above 5 lines of code are not needed except to save time\n",
    "    wins=[]\n",
    "    ties=[]\n",
    "    losses=[]  \n",
    "    # iterate through all possible next moves\n",
    "    for m in env.validinputs:\n",
    "        # make a hypothetical move and see what happens\n",
    "        env_copy=deepcopy(env)\n",
    "        new_state, reward, done, info = env_copy.step(m) \n",
    "        # If player O wins right away with move m, take it.\n",
    "        if done and reward==-1:\n",
    "            return m \n",
    "        # See what's the best response from the opponent\n",
    "        opponent_best = best_outcome(env_copy, reward, done)  \n",
    "        # Opponent's payoff is the opposite of your payoff\n",
    "        my_payoff = -1*opponent_best \n",
    "        if my_payoff==1:\n",
    "            wins.append(m)\n",
    "        elif my_payoff==0:\n",
    "            ties.append(m)\n",
    "        else:\n",
    "            losses.append(m)\n",
    "    # pick winning moves if there is any        \n",
    "    if wins:\n",
    "        return choice(wins)\n",
    "    # otherwise pick tying moves\n",
    "    if ties:\n",
    "        return choice(ties)\n",
    "    return choice(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b208ef",
   "metadata": {},
   "source": [
    "To speed up the game, we choose Cell 5 or Cell 1 as the first move for player O, depending on player X's first move. If we don't do this, the first move for player O takes 5 to 10 seconds. You can try to delete this part of the code and see what happens.\n",
    "\n",
    "Recall that in the Tic Tac Toe game environment we created, whenever player O wins, the variable *reward* has value -1. Therefore, we have changed \n",
    "```python\n",
    "        if done and reward==1:\n",
    "            return m \n",
    " ```\n",
    " to \n",
    " \n",
    " ```python\n",
    "        if done and reward==-1:\n",
    "            return m \n",
    "            \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58df6cd7",
   "metadata": {},
   "source": [
    "### 3.2. Test the Efficacy of the Minimax Algorithm\n",
    "Next, weâ€™ll test how often the Minimax Algorithm wins against the deep-learning game strategy that we developed in Chapter 11, when the minimax agent moves second.\n",
    "\n",
    "The following script does that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cb92577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of winning games for player X is 0\n",
      "the number of tying games is 100\n",
      "the number of losing games for player X is 0\n"
     ]
    }
   ],
   "source": [
    "from utils.TicTacToe_env import ttt\n",
    "import time\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a deep learning game strategy for player O based on Chapter 11\n",
    "reload = tf.keras.models.load_model('files/ch11/trained_ttt100K.h5')\n",
    "def DL_move_X(board, valids):\n",
    "    # if there is only one valid move, take it\n",
    "    if len(valids)==1:\n",
    "        return valids[0]\n",
    "    # Set the initial value of bestoutcome        \n",
    "    bestoutcome = -1;\n",
    "    bestmove=None    \n",
    "    #go through all possible moves hypothetically to predict outcome\n",
    "    for move in valids:\n",
    "        tooccupy=deepcopy(board).reshape(9,)\n",
    "        tooccupy[int(move)-1]=1\n",
    "        prediction=reload.predict(np.array(tooccupy).reshape(-1, 3,3,1), verbose=0)\n",
    "        # We use the winning prability of player O minus that of player X\n",
    "        win_lose_dif=prediction[0][1]-prediction[0][2]\n",
    "        if win_lose_dif>=bestoutcome:\n",
    "            # Update the bestoutcome\n",
    "            bestoutcome = win_lose_dif\n",
    "            # Update the best move\n",
    "            bestmove = move\n",
    "    return bestmove\n",
    "\n",
    "\n",
    "env=ttt()\n",
    "\n",
    "def test_one_game():\n",
    "    state=env.reset()   \n",
    "    while True:\n",
    "        # the minimax agent moves first\n",
    "        action = DL_move_X(state,env.validinputs)   \n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            break \n",
    "        # the deep learning agent moves second\n",
    "        action = minimax_O()   \n",
    "        new_new_state, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "        else: \n",
    "            # play next round\n",
    "            state=new_new_state\n",
    "    return reward\n",
    "\n",
    "#repeat the game 100 times and record all game outcomes\n",
    "results=[]        \n",
    "for x in range(100):\n",
    "    result=test_one_game()\n",
    "    results.append(result)    \n",
    "\n",
    "#print out the number of winning games\n",
    "print(\"the number of winning games for player X is\", results.count(1))\n",
    "\n",
    "#print out the number of tying games\n",
    "print(\"the number of tying games is\", results.count(0))\n",
    "\n",
    "#print out the number of losing games\n",
    "print(\"the number of losing games for player X is\", results.count(-1))                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060fa1bb",
   "metadata": {},
   "source": [
    "The minimax agent ties all 100 games when playing second. It shows two things:\n",
    "\n",
    "* The minimax agent is unbeatable;\n",
    "* The deep learning game strategies we developed in Chapter 11 are highly effective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a3674b",
   "metadata": {},
   "source": [
    "## 4. Deploy the Minimax Algorithm Online\n",
    "Now that we have created a perfect game player using artificial intelligence, we want to deploy it online so that people can play against it and see how powerful it is. \n",
    "\n",
    "One way to do this is by using JavaScript. But an easier way is to use an online platform that hosts applications in different coding languages. So I have chosen replit.com. \n",
    "\n",
    "I made a couple of changes before deploying the minimax agent. \n",
    "* First, I made the game window smaller. The replit.com platform allows a game window of about 400 pixels tall, so I made the game window 350 by 350 pixels so you can see the whole game window on your device.\n",
    "* Second, I made the game interface touch-screen. That is, you don't need to play the game by using keyboard inputs. Instead, you can play by using your touch screen or a mouse click. This is especially important in the age of cell phones and tablets. \n",
    "* Third, I added a message box whenever the game is over. Further, if you make an invalid move (e.g., touch a cell that's already occupied), the program will pop up a message to let you know and you can keep your turn and make a valid move after that. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d2dd43",
   "metadata": {},
   "source": [
    "### 4.1. The Whole Program to Deploy\n",
    "Again, we'll use the self-made Tic Tac Toe game environment from Chapter 11. Specifically, the module is saved as *TicTacToe_env.py* in the folder utils in this GitHub repository. I renamed it *TTT_env.py* before uploading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0df744",
   "metadata": {},
   "source": [
    "The *main.py* program I uploaded to replit.com is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d85158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import messagebox\n",
    "import turtle as t\n",
    "import TTT_env \n",
    "import time\n",
    "import random\n",
    "from random import choice\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "# Initiate the game environment\n",
    "env=TTT_env.ttt()\n",
    "state=env.reset()   \n",
    "\n",
    "def best_outcome(env,reward, done):\n",
    "    if done:\n",
    "        if reward==1 and env.turn==\"O\":\n",
    "            return 1\n",
    "        if reward==1 and env.turn==\"X\":\n",
    "            return -1\n",
    "        if reward==-1 and env.turn==\"O\":\n",
    "            return -1\n",
    "        if reward==-1 and env.turn==\"X\":\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    best = -1\n",
    "    for m in env.validinputs:\n",
    "        env_copy=deepcopy(env)\n",
    "        new_state, reward, done, info = env_copy.step(m)      \n",
    "        opponent_best = best_outcome(env_copy, reward, done)         \n",
    "        our_best = -1*opponent_best \n",
    "        if our_best > best:        \n",
    "            best = our_best\n",
    "    return best\n",
    "\n",
    "def best_move():\n",
    "    if env.occupied[\"O\"]==[]:\n",
    "        if env.occupied[\"X\"]==[\"5\"]:\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"5\"\n",
    "    wins=[]\n",
    "    ties=[]\n",
    "    losses=[]       \n",
    "    for m in env.validinputs:\n",
    "        env_copy=deepcopy(env)\n",
    "        new_state, reward, done, info = env_copy.step(m)\n",
    "        if done and reward==-1:\n",
    "            return m\n",
    "        opponent_best = best_outcome(env_copy, reward, done)         \n",
    "        our_best = -1*opponent_best \n",
    "        if our_best==1:\n",
    "            wins.append(m)\n",
    "        elif our_best==0:\n",
    "            ties.append(m)\n",
    "        else:\n",
    "            losses.append(m)                      \n",
    "    if wins:\n",
    "        return choice(wins)\n",
    "    if ties:\n",
    "        return choice(ties)\n",
    "    return choice(losses)\n",
    "\n",
    "# Set up the screen\n",
    "t.setup(350,350)\n",
    "t.tracer(False)\n",
    "t.bgcolor(\"azure\")\n",
    "t.title(\"Tic-Tac-Toe Minimax Agent\")\n",
    "# Draw horizontal lines and vertical lines to form grid\n",
    "t.pensize(5)\n",
    "for i in (-150,-50,50,150):  \n",
    "    t.up()\n",
    "    t.goto(i,-150)\n",
    "    t.down()\n",
    "    t.goto(i,150)\n",
    "    t.up()\n",
    "    t.goto(-150,i)\n",
    "    t.down()\n",
    "    t.goto(150,i)\n",
    "    t.up()\n",
    "# Create a dictionary to map cell number to the cell center coordinates\n",
    "cellcenter = {'1':(-100,-100), '2':(0,-100), '3':(100,-100),\n",
    "            '4':(-100,0), '5':(0,0), '6':(100,0),\n",
    "            '7':(-100,100), '8':(0,100), '9':(100,100)} \n",
    "\n",
    "# The X player moves first\n",
    "turn = \"X\"\n",
    "# Count how many rounds played\n",
    "rounds = 1\n",
    "# Create a list of valid moves\n",
    "validinputs = list(cellcenter.keys())\n",
    "# Determine if a player has won the game\n",
    "occupied = {\"X\":[],\"O\":[]}\n",
    "t.pencolor(\"gray\")\n",
    "\n",
    "# Determine if a player has won the game\n",
    "def WinGame():\n",
    "    win = False\n",
    "    if '1' in occupied[turn] and '2' in occupied[turn] and '3' in occupied[turn]:\n",
    "        win = True\n",
    "    if '4' in occupied[turn] and '5' in occupied[turn] and '6' in occupied[turn]:\n",
    "        win = True\n",
    "    if '7' in occupied[turn] and '8' in occupied[turn] and '9' in occupied[turn]:\n",
    "        win = True\n",
    "    if '1' in occupied[turn] and '4' in occupied[turn] and '7' in occupied[turn]:\n",
    "        win = True\n",
    "    if '2' in occupied[turn] and '5' in occupied[turn] and '8' in occupied[turn]:\n",
    "        win = True\n",
    "    if '3' in occupied[turn] and '6' in occupied[turn] and '9' in occupied[turn]:\n",
    "        win = True\n",
    "    if '1' in occupied[turn] and '5' in occupied[turn] and '9' in occupied[turn]:\n",
    "        win = True\n",
    "    if '3' in occupied[turn] and '5' in occupied[turn] and '7' in occupied[turn]:\n",
    "        win = True\n",
    "    return win\n",
    "\n",
    "\n",
    "# Define a function mark_cell() to place a dot in the cell\n",
    "def mark_cell(x,y):\n",
    "    global turn, rounds, validinputs, state\n",
    "    # Calculate the cell number based on x and y values\n",
    "    if -150<x<150 and -150<y<150:\n",
    "        col = int((x+250)//100)\n",
    "        row = int((y+250)//100)\n",
    "        # The cell number is a string varibale\n",
    "        cellnumber = str(col+(row-1)*3)\n",
    "    else:\n",
    "        print('you have clicked outside the game board')\n",
    "    # Check if the move is a valid one\n",
    "    if cellnumber in validinputs:\n",
    "        # Go to the corresponding cell and play\n",
    "\n",
    "        \n",
    "        if turn==\"O\":\n",
    "            t.up()\n",
    "            t.goto(cellcenter[cellnumber])\n",
    "            t.dot(80,\"light gray\")\n",
    "        if turn==\"X\":\n",
    "            t.up()\n",
    "            t.goto(cellcenter[cellnumber][0]-30,cellcenter[cellnumber][1]-30)\n",
    "            t.down()               \n",
    "            t.goto(cellcenter[cellnumber][0]+30,cellcenter[cellnumber][1]+30)\n",
    "            t.up()\n",
    "            t.goto(cellcenter[cellnumber][0]-30,cellcenter[cellnumber][1]+30)\n",
    "            t.down()               \n",
    "            t.goto(cellcenter[cellnumber][0]+30,cellcenter[cellnumber][1]-30)\n",
    "            t.up()           \n",
    "        t.update()\n",
    "        # Add the move to the occupied list for the player\n",
    "        occupied[turn].append(cellnumber)\n",
    "        # Disallow the move in future rounds\n",
    "        validinputs.remove(cellnumber)\n",
    "        # Check if the player has won the game\n",
    "        if WinGame() == True:\n",
    "            # If a player wins, invalid all moves, end the game\n",
    "            validinputs = []\n",
    "            messagebox.showinfo(\"End Game\",f\"Congrats player {turn}, you won!\")\n",
    "        # If all cellls are occupied and no winner, it's a tie\n",
    "        elif rounds == 9:\n",
    "            messagebox.showinfo(\"Tie Game\",\"Game over, it's a tie!\")\n",
    "        # Counting rounds\n",
    "        rounds += 1\n",
    "        # Give the turn to the other player\n",
    "        if turn == \"X\":\n",
    "            turn = \"O\"\n",
    "        else:\n",
    "            turn = \"X\"     \n",
    "    # If the move is not a valid move, remind the player \n",
    "    else:\n",
    "        messagebox.showerror(\"Error\",\"Sorry, that's an invalid move!\")      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # minimax agent moves  \n",
    "    action = cellnumber    \n",
    "    new_state, reward, done, info = env.step(action)\n",
    "    t.update()\n",
    "    if not done:   \n",
    "        action = best_move()   \n",
    "        new_new_state, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(f\"Player O has won!\") \n",
    "        else: \n",
    "            # play next round\n",
    "            state=new_new_state\n",
    "        cellnumber = action   \n",
    "        if turn==\"O\":\n",
    "            t.up()\n",
    "            t.goto(cellcenter[cellnumber])\n",
    "            t.dot(80,\"light gray\")\n",
    "        if turn==\"X\":\n",
    "            t.up()\n",
    "            t.goto(cellcenter[cellnumber][0]-30,cellcenter[cellnumber][1]-30)\n",
    "            t.down()               \n",
    "            t.goto(cellcenter[cellnumber][0]+30,cellcenter[cellnumber][1]+30)\n",
    "            t.up()\n",
    "            t.goto(cellcenter[cellnumber][0]-30,cellcenter[cellnumber][1]+30)\n",
    "            t.down()               \n",
    "            t.goto(cellcenter[cellnumber][0]+30,cellcenter[cellnumber][1]-30)\n",
    "            t.up()           \n",
    "        t.update()\n",
    "        # Add the move to the occupied list for the player\n",
    "        occupied[turn].append(cellnumber)\n",
    "        # Disallow the move in future rounds\n",
    "        validinputs.remove(cellnumber)\n",
    "        # Check if the player has won the game\n",
    "        if WinGame() == True:\n",
    "            # If a player wins, invalid all moves, end the game\n",
    "            validinputs = []\n",
    "            messagebox.showinfo(\"End Game\",f\"Congrats player {turn}, you won!\")\n",
    "        # If all cellls are occupied and no winner, it's a tie\n",
    "        elif rounds == 9:\n",
    "            messagebox.showinfo(\"Tie Game\",\"Game over, it's a tie!\")\n",
    "        # Counting rounds\n",
    "        rounds += 1\n",
    "        # Give the turn to the other player\n",
    "        if turn == \"X\":\n",
    "            turn = \"O\"\n",
    "        else:\n",
    "            turn = \"X\"     \n",
    "     \n",
    "# Hide turtle so that you don't see the arrowhead        \n",
    "t.hideturtle()\n",
    "# Bind the mouse click to the mark_cell() function\n",
    "t.onscreenclick(mark_cell)\n",
    "t.listen()    \n",
    "t.done()\n",
    "try:\n",
    "    t.bye()\n",
    "except t.Terminator:\n",
    "    print('exit turtle')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507a0fe6",
   "metadata": {},
   "source": [
    "### 4.2. A Screenshot of the Deployed Game\n",
    "Here is the outcome of a game that's played on the replit platform. "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5ea21ada",
   "metadata": {},
   "source": [
    "The link to the deployed game player on replit.com is here:\n",
    "\n",
    "https://replit.com/@MarkLiu11/Tic-Tac-Toe-Minimax-Solver?v=1\n",
    "\n",
    "Below is the outcome of a game in which the minimax agent (Player O) has won.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "You are welcome to play there. If you won the game, please let me know: it means there is a bug in my program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97c5efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
