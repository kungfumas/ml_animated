{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "653089c9",
   "metadata": {},
   "source": [
    "# Chapter 18: Double Deep Q Learning\n",
    "\n",
    "Deep Q learning has a well-known problem of overestimating Q values. In most cases, this is not an issue since we only care about the relative magnitude of the Q-values for different actions. However, in complicated situations such as Atari games, this poses a problem and leads to wrong actions in certain scenarios. \n",
    "\n",
    "To overcome this, we need to use double Q learning: we'll use one deep Q network for training and another deep Q network for predicting, and periodically updated the target Q network with the weights from the training Q network. \n",
    "\n",
    "The double deep Q learning can play Atari Games very efficiently. You’ll learn to create a deep neural network with convolutional layers to extra features from the Atari gameplay screenshots. You’ll use the Atari Breakout game as an example in this chapter. It can eliminate almost all bricks on the screen. \n",
    "\n",
    "More important, the agent sends the ball to the back of the wall multiple times once there is at least one opening to the back of the wall. The agent has definitely \"learned\" that it's more efficient to earn points that way than directly aiming at the bricks.\n",
    "\n",
    "Furthermore, the model is highly scalable, and you can tweak the model slightly and apply to other Atari games such as SpaceInvaders, Seaquest, Pong, and BeamRiders, as you’ll see in the next few chapters. \n",
    "\n",
    "The model used in this chapter is largely based on the example script by Jacob Chapman and Mathias Lechner https://keras.io/examples/rl/deep_q_network_breakout/. I made some minor changes to shorten the script, such as using the *deque()* method from the ***collections*** library so that we don't have to keep track of the size of the memory buffer or the size of the running rewards. \n",
    "\n",
    "In the left frame of the animation below, you can see that the agent has sent the ball to the back of the wall five consecutive times. It's clear that the agent has \"learned\" to do this on purpose because this is a more efficient way of earning rewards than aiming at the bricks directly: \n",
    "<img src=\"https://gattonweb.uky.edu/faculty/lium/ml/breakout_highlights.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b25bf6",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{Create a subfolder for files in Chapter 18}}$<br>\n",
    "***\n",
    "We'll put all files in Chapter 18 in a subfolder /files/ch18. The code in the cell below will create the subfolder.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "117477d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"files/ch18\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaf7558",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{Install OpenAI Baselines for Chapter 18}}$<br>\n",
    "***\n",
    "We'll use OpenAI Baselines to train several Atari games from this chapter onwards. The Baselines library provides high quality implementations of reinforcement learning algorithms and it makes our training of complicated Atari games more effective. For more details, go to https://github.com/openai/baselines.\n",
    "\n",
    "To install OpenAI Baselines, make sure that you have installed atari_py and ROMS on your computer. If not, refer to Chapter 16 on how to install. \n",
    "\n",
    "Also, make sure you are using version 0.15.7 of the OpenAI Gym environment. In case you accidentally installed a different version, run the following lines of code to correct it.\n",
    "\n",
    "`pip uninstall gym`\n",
    "\n",
    "`pip install gym==0.15.7`\n",
    " \n",
    "\n",
    "Here are the steps to install OpenAI Baselines:\n",
    "* Step 1: Make sure you have Git installed on your computer; if not, see instructions here https://git-scm.com/book/en/v2/Getting-Started-Installing-Git. \n",
    "* Step 2: Open the Anaconda prompt (Windows) or a terminal (MAC or Linux) and activate the virtual environment ***animatedML***. Clone the OpenAI Baselines repository by running the following line of command:\n",
    "\n",
    "`git clone https://github.com/openai/baselines.git`\n",
    "\n",
    "* Step 3: Go into the baselines directory by running the following line of command:\n",
    "\n",
    "`cd baselines`\n",
    "\n",
    "* Step 4: Install the baselines package in the virtual environment by running the following command:\n",
    "\n",
    "`pip install -e .`\n",
    "\n",
    "Make sure you don't miss the dot at the end of the above command. \n",
    "\n",
    "After that, restart your Jupyter Notebook for the package to take effect.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7dbb5c",
   "metadata": {},
   "source": [
    "## 1. Get Started with the OpenAI Baselines\n",
    "\n",
    "In this section, you'll learn the special features of OpenAI Baselines. I'll focus on the features that are different from the game without using the baselines package. For comparison, we'll use the Breakout game since you have already used it in Chapter 17."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b7aaab",
   "metadata": {},
   "source": [
    "### 1.1. The Breakout Game with OpenAI Baselines\n",
    "\n",
    "Remember in Chapter 17 we need to reconfigurate the rewards by counting the number of lives remaining for the agent? Well, with the baselines game wrapper, the agent has one life in each episode. That is, each time the agent loses a life (i.e., the paddle misses the ball), the episode ends. In the original Atari Breakout game, the agent starts with 5 lives and the episode ends when the agent loses all 5 lives. \n",
    "\n",
    "This makes reconfiguring the reward system much easier. Each time the game ends (i.e., done==True), we set the Q-value to -1. This is crucial for the success of the training. \n",
    "\n",
    "Let's make sure that's indeed the case. Run the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adfa3a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.0 False {'ale.lives': 5}\n",
      "2 0.0 False {'ale.lives': 5}\n",
      "3 0.0 False {'ale.lives': 5}\n",
      "3 0.0 False {'ale.lives': 5}\n",
      "3 0.0 False {'ale.lives': 5}\n",
      "1 0.0 False {'ale.lives': 5}\n",
      "0 0.0 False {'ale.lives': 5}\n",
      "3 0.0 False {'ale.lives': 5}\n",
      "2 0.0 False {'ale.lives': 5}\n",
      "0 0.0 False {'ale.lives': 5}\n",
      "3 0.0 False {'ale.lives': 5}\n",
      "1 0.0 False {'ale.lives': 5}\n",
      "3 0.0 False {'ale.lives': 5}\n",
      "1 0.0 False {'ale.lives': 5}\n",
      "3 0.0 False {'ale.lives': 5}\n",
      "3 0.0 False {'ale.lives': 5}\n",
      "0 0.0 False {'ale.lives': 5}\n",
      "0 0.0 False {'ale.lives': 5}\n",
      "1 0.0 False {'ale.lives': 5}\n",
      "2 0.0 False {'ale.lives': 5}\n",
      "3 0.0 False {'ale.lives': 5}\n",
      "2 0.0 False {'ale.lives': 5}\n",
      "2 0.0 True {'ale.lives': 4}\n"
     ]
    }
   ],
   "source": [
    "from baselines.common.atari_wrappers import make_atari, wrap_deepmind\n",
    "\n",
    "# Use the Baseline Atari environment\n",
    "env = make_atari(\"BreakoutNoFrameskip-v4\")\n",
    "# Process and stack the frames\n",
    "env = wrap_deepmind(env, frame_stack=True, scale=True)\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    # randomly pick actions\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(action, reward, done, info)\n",
    "    # Render the env\n",
    "    env.render()\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e26b04e",
   "metadata": {},
   "source": [
    "As you can see, the agent starts with 5 lives. Once the agent loses one life, the variable done becomes True and the episode ends. Note that the reward is still 0, but we can code it as -1 by using this line of code; you'll see it in the script for training later:\n",
    "\n",
    "```python\n",
    "    # Each time the agent loses a life, set Q to -1; important\n",
    "    new_Qs = Qs * (1 - dones) - dones\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afebfcb",
   "metadata": {},
   "source": [
    "Run the following to close the game window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb2f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20db9147",
   "metadata": {},
   "source": [
    "### 1.2. Preprocessed Frames from the OpenAI Baselines\n",
    "\n",
    "Remember in Chapters 16 and 17 we need to preprocess raw images from the Pong and Breakout games by cropping, downsizing, and differencing the images? Well, the baselines game wrapper does all those for you. In each time step, it returns four consecutive frames of preprocessed images, each with a size of 84 by 84.  \n",
    "\n",
    "Let's visualize the preprocessed images from the baseline package. Run the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02285e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdYklEQVR4nO3da5BkZ33f8e//Oef0dW47s/eLtFrtSkJG0QUZoYjEWJgYMAUuFyFgikq5SPQijgPGFQzOi4SqvDBVKQOVIlAqLlGlCAJkbiXbOFiGOFjUotUFkLQSWq2k1d5nd+7d093n8s+Lc1Y7uzsz27PdPdOz5/+pmprp093nPD09vznPec7p5y+qijHm6ufWugHGmNVhYTcmJyzsxuSEhd2YnLCwG5MTFnZjcqKjsIvI20XkeRE5JCKf6FajjDHdJ1d6nl1EPOBXwNuAo8BjwAdU9dnuNc8Y0y1+B899I3BIVQ8DiMiDwHuAJcNekKKWqHawSWPMchrUaGlTFruvk7DvAF5dcPsocNdyTyhR5S55awebNMYsZ78+suR9nYS9LSJyH3AfQIlKrzdnjFlCJwN0x4BdC27vzJZdQFXvV9U7VfXOgGIHmzPGdKKTPftjwD4RuY405O8Hfr8rreo3IiAOCXy8zZvQoYvGHaIY4vjCZc6B76XPPbea+SZ6ZgJttdAoQqMICQp4YxugWEADH4qF9MFJAnFy/udz6xQBJ+nPAK0QmW9CFJFMTZM0GojvI8UiEvjI8BA6kPWozg3Gxsni7Q0u/HOQ+SbJ8ZMkjcaV/NbaJr6PGx4C30cqZbRSOt9e1bS9534Hiz0/itPHhCHx5BTabPa0vYtyHt7wEFIpQ+Cj5SI4h9QbaH0+fX+mZ9AoWv22Za447Koaici/B/4W8ICvqOozXWtZH3HFIjI4CBtHOPy+TQy+cfy1+1SFyZkB4pkCLDixIZWIgeF5fJfgOUVEOfPiFnY/vJHSsVnkzCTxqdN4Wzdz4l27mNsF4VjEyNZZnEuYq5eJWh5J5KDppSstxnjFGM9LqJRaBH7M+PExKi8FFKZh6/+bgF88h9uwgWjfdlrDBU7c4zNw61mcQCvySFSYrxeJZ4O0vXK+vcPDdQL//D+BM4e3cOOXK/BUb0+weFu3MHX3Thqjjul9ytANk4gojVZAFHnp76EWXPD7fY2CP+sRzAnFCdj2d6eJnz/U0/Yu+hoGqsz+5g1M7fVojCrB3lmKQcTsr7YzfAhKEwkjPz1KdPSSzu+q6eiYXVX/GvjrLrWlfwUBUikRjlTwbp3m27d8lSx+hMCj87t4dHYviZ4/Knpd9Tj3lA9RcRElUQLgP254F7964nV49TKF2jyIoIMVpm9QNt80zpu3HObfjv2EAOXZcCPHwlGm4zLHmhtIVNhVmmB7MMWIV2OPP8GgS/jijrv5RvUNzI+XGHumggdIpcT8lhLzY46h287yzVu+gicwlfg01OPZ5g6eql1DlHj4LsYjYV/5FL9ReYERd34P+mdj7+DId2/o+cCOVsvMXOsxvzXhhjcc4bN7vkWAcjyuMJVUeLU1xgvzW2gmwSXPTRCen97M8clhpk9U2PRElUWHonutWGRml0ft5ibX7jjDp67/Hlu9Gn808K94UXYSnvAY/kV5LVr2mp4P0F3tQoVvj9/BgZ/vhejcblJ5fN9Odu09yw5/Cs+1CFbwF1hXjx/PvI4DZ6/hzFyVuVMDSCRUts9x06ZT7KxM8XsbDjDo5tpeZ0OF49EwU3GFh06+gWcO7kJCQQsKnrLrmjPcsu9VRlx9hb+B3ggRjkUbOBWO8HRtO0+c3kUz8i55nKpQmynBdEBp3MOrt1i6w59vFvYONdTjwFN7uenzE+mxM4AIR/7lDn6x4xooQxBMUJH2j9XOJmX+6vCvoU8PUTmu3PSzaaTe5PQ/28wTtw7wyy3z3HHry+zx2w97PfF5trGDI81RnntsNzc9MImrN4iHqyRln6Nv3cbLuzexx39lpb+Cnmiox8H5HbxY38iTJ3fSPDiM17j0P6YoDNTBryvFqQQ3XbOwL8HC3qEYwZtz6CvHiOvZXlGEwvR26nGBUH0SXVnHMlFHsxFQnYXSlCJHT5HMzlF+/Ub8uiNs+DS0sOJ21pMCtahIMCfI0RNEM3N4m8bwKmWC2SqNRbrJq0IVF4GLhLlWkZNxlXpS5FRriNPzg8zXixTnBK8J6gBJv6sDFUBBkjT4ZmkWdrPmpDbP0CsxhRnHyWQr901/CFWhNVuAlsOf9ZA4DXc4AHFZiYYjdlx7lpHSPMemh5mcruCdKDL04jC8vNavqD9Z2M2a01qN6tE6xakAv1GgdnYQdVBYeHZDIfEhqijxSMTo1mk+fv0PuKVwmkcb1/LTmb38w9AeWsMV1qh/0vcs7B3yUKLNIa27X4fXSE9bqcDcLtgYzFF1TQJZ2VFkIBGjIzUmtxdJfEfw63vwGzFTezzCTS1GRuoMufkVrjNhg1+jUQxobI2Yv2sffiOmWfWJS476NmXQW9k6u8b3iSs+4YBPY8TR2KgsduSjHsSjIcXBJpuqNYZcg0DAI8FJko7CuzUZi18XLOwdqkjMe297nL8ZuZk4Pn/q7fbtz3NH+WVGvToViZdZw6U2efN8YPcBntm4nVONQY7cPUIcO64dPcmvDZ9gc2GGfYVTK1pnVSJuKb3K7sI4U3dW+L9bryeOHb7fwBPl7s3HuT4Yv/yKekDKZea2F9Pz7DfG7LzxNIF36e/Ml4SxUo3RQp1dpQlGvf44c7BeWNgvRy7cUySJUFfBy67wiBFuKp9gZmfpgvPsN1RPUpIQgIY6EhJaiXfhhSGSPV4hThzNxKee+ASScG3hDG4w4bpKiWuqI8QqbC9Os7MwwaA3j4dSV6GZ+KgKr3UeRM63WSFOhLp6OJQCMYOuweurR0l2CmHiEbgYh7KnPJ6t83zzmvEq/Xn4HnFRiMqg1ZhrBicpe+ElD3OSMBLMM+g12ODXCNVRV6GhAc1k5QOhXeUEUdBECGOPelKkLk0idUgii18QtMqu+PPsV2K4uEX/6fYPrtr2ukULAVouEA+WOHpvhfB1dSQb+lUVolqAq10Y5KSc4Koh4kAkvYIuOVph26MJpTMt/Ol53EydeOMQp940xPxmpTWsuI1NECVu+NBykIBrOVBIigkECk7xSjEiSny2SPm4RzAHG3/ZoPjSOMlwlfkdg0RVx9nXe4Q31BEgiQVVQec93Lz32hV0KqDFBG8wxC24qCY5Vmb3X7UoHu7tHj8ZGWDu+iFaVUd9qzC/NUGX+NSG+op6Cr7iKhHO6Wu//8KEY/tPmpRePN3T9i7arkqJydvHmNvpaA0r4Y4WLkhwr5SoHhWKMwkjB2fxzsz0tB2PHv8a081Ti/7XW9WwDw3u0F+//d+t2va6SgQcxIEjCS78SxTl/HXnFz1n4c7GxYprJYgqJNlzREgKDvXSx2p2zPnaaaSL15vttc+tVxJFYkUUXJRAnK5TPQGBxJML2rvkejm/7YXt9Zpxus5eWtBedULit7GHXvC7Pff7l1jxwqT37V2CBg516WtRl7bPxYpEimj6fdG/ky567Mn/wczssa5/nn3F4qJj5rq1vWTQrJSNba8n8bNLf5B1VcNe2Nhk130vrOYmjcmVQ/uX/sTfqob9msIk//3a767mJo3JlXcWJpe8z6aSNiYnLOzG5ISF3ZicsLAbkxOXDbuIfEVETovI0wuWjYrID0Xkhez7ht420xjTqXb27P8TePtFyz4BPKKq+4BHstvGmD522bCr6j8AExctfg/wQPbzA8DvdrdZxphuu9Jj9i2qeiL7+SSwpUvtMcb0SMcDdJpeXL/kBb8icp+IHBCRA2cnbHYwY9bKlYb9lIhsA8i+L/kxo4UVYcZGbfDfmLVypZfLfh/418CfZ9+/17UWAQ1NPwMO6bzgxuSVyzrNJUkodRiFy4ZdRL4OvAXYKCJHgf9MGvJvisiHgVeA93XWjPNC4HA0zMutTYTq0dDggkkhjMkLJwklCQkkZndhnH3BdEefQbxs2FX1A0vc1bPay2fjAY60xggTj7m4SKSXFgcw5mrnS8yA16ToIga9efYF052tr0vt6ppa4vju+B3sP7ybpOnh5nwktK68yR8NlGQgwhVj7r7+JW7ZfuKC8lwr1Xdhn06K/PSZvez8gSOYiSgdGUdqazTrqTFrSKtlGrs30Bos8I/v2MvstoARrrxCbd+FPUaQhqM4GeJPNdETp4lnZ9e6WcasOm9oiEK1hAuLSKPzsSsb+TImJyzsxuSEhd2YnLCwG5MTFnZjcsLCbkxOWNiNyQkLuzE5YWE3Jics7MbkhIXdmJywsBuTExZ2Y3LCwm5MTrRTEWaXiPxIRJ4VkWdE5CPZcqsKY8w60s6ePQL+RFVvBt4E/KGI3IxVhTFmXWmnIswJVX0i+3kWOAjswKrCGLOurOiYXUR2A7cD+2mzKowViTCmP7QddhEZAP4S+Kiqziy8b7mqMFYkwpj+0Fb6RCQgDfrXVPXb2eK2q8IYY9ZeO0UiBPgycFBV/2LBXT2pCuOh4EFccHhFD1cp48KwG6s2Zn0pl0hKPnHRQz3FSWeHwe3MLnsP8CHglyLyVLbsz+hRVRgnCVqOaYz5JAVHpbERGR7sxqqNWVeSaonmxiKtQYeUw3RH2IF2KsL8BJYsuNaTqjAuiAnLARI7osEinmdFIkz+xJUCYdURlgUXdD643Xfzxpck5pqtExx5/Ta8pjBzXRnXKq91s4xZdUkBWiNKXFT2bD1DSeKO1td3YR+UiN/b/hSPDUzSiANmWiXCxGq9mfwJXMxQoUHJC7lr+CUqV1vYAYa9GluKszQTn6rfsrCbXApczKDfoOgiRrx6x+uzE9/G5ISF3Zic6LtuvCdQdS2G/XkaSYATJbJuvMkh36X12UsupCQhnZ6U6ruwA4x5c1xTOEOoPvWkSLzkmT9jrl4eSsU1CSRizJvruBved2F3QCARVdci1HT0MbajDZNDHglV1ySQmECijtfXd2EHCCSm5Fp4mjavpdaNN/lTkJiSCwkkIujwtBv0adg9lIA4vW7PgVP7aKzJn4LElCTEkXR8qSz0adjP8VDC7LsxpjN9HXYAR7L0lfnGXMUc3e3R2siXMTnRl3t2D8WTBBQ8kSXmwDHm6uZJkh6vy1V+zO6hIAmJOujwQ/vGrEfndnrdGrOybrwxOWFhNyYn2qkIUxKRn4nIz7OKMJ/Kll8nIvtF5JCIfENECr1vrjHmSrVzzN4E7lXVuWyW2Z+IyN8AHwM+o6oPisgXgQ8DX+i0QR5QcRFO6iQqdl28yTUPxYlSkphOryNtZw46Beaym0H2pcC9wO9nyx8A/gtdCDvAJicEAqA4C7vJsSQbnAtVaGiPJ5wEEBEPeBzYC3weeBGYUtVzV+cfJS0Jtdhz7wPuA9ix4/JDBJ4IgTjK2VGBJzasYPIrfu1S8RYhStxB4NtKkqrGqnobsBN4I3BTuxuwijDG9IcVpU9Vp4AfAXcDIyJyrmewEzjW3aYZY7qpnYowm4BQVadEpAy8Dfg0aejfCzxIFyvCxKqEJEALAKfWGzD5lWTXx4eadNSFh/aO2bcBD2TH7Q74pqo+LCLPAg+KyH8FniQtEdUVE0lCQ9OBubjLHwYwZj05d/VcSRIqvZ6WSlV/QVqm+eLlh0mP37sqBhrqMZsUiBGbpcbkWoFs0grXotjh6be+vDa+oR4zSYkER0s9Egu8ySFHQkFiHAmBxAxzFRaJaKjPVFIhVJ9aUiRRO9du8seJZnPQRVRdk3PjWFeq78KeAKH62Zf32pcxeRMQv/a3343D2b4LO0BNC0xEA4TqMRuXSOwqOpNDDqXpBQQSM+bNkTB39R2zp/PFFwjVo54UiBI7Zjf547t04opA4q7MsNx3YY8VTkdDvNIYoxn7TIclqwhjcsl3McNBg6IXsdGfJS6czj4zcoXr617TuiNEeLGxmZ+f3U4j9KnNF0li27Ob/HFeQrXcpBREjPh13lI51NH6+i7sAM3EZ74V0Ip8wpaPxnbMbvJHPEfTTy8qayZ+9nHvHn8Qxhiz/lnYjcmJvuvGxyqcbAwxNVlFWx5u1sMLrRtv8icJlNqgT70Qc2J0mFgF5Mq78X0X9rr6PHVsB4NPlghqSmU8xpu3D8OY/InLjvomn7Aa8FR1B83tHnTwwbC+C3uM0KwVGBlPKMwlVI7UcPXmWjfLmFWXVIqgVVoDjtlaoeP5GPsu7Ik6aDmCuhLMxnjTNbRWX+tmGbPqXFwlmCuhTtCWd/WFPUaQlqMwHRFMN9CJSeLpmbVuljGrzms2CUaqAEir86j2XdgBUBBVSEDjBDqcocOYdSlRiBVJFDTr9XbATr0ZkxNth11EPBF5UkQezm5bRRhj1pGV7Nk/AhxccPvTpBVh9gKTpBVhjDF9qq2wi8hO4HeAL2W3hbQizEPZQx4AfrcH7TPGdEm7e/bPAh/n/Bn9MVZQEUZEDojIgbMTdnGMMWulnSqu7wJOq+rjV7IBqwhjTH9o59TbPcC7ReSdQAkYAj5HVhEm27tbRRhj+txld7Wq+klV3amqu4H3A3+vqh/kfEUY6GJFGGNMb3TSr/5T4GMicoj0GL5rFWGMMd23oivoVPXHwI+zn3tSEcYY0xs2YmZMTljYjckJC7sxOWFhNyYnLOzG5ISF3ZicsLAbkxMWdmNywsJuTE5Y2I3JCQu7MTlhYTcmJyzsxuSEhd2YnLCwG5MTFnZjcsLCbkxOtDVTjYi8DMwCMRCp6p0iMgp8A9gNvAy8T1Une9NMY0ynVrJn/01VvU1V78xufwJ4RFX3AY9kt40xfaqTbvx7SCvBgFWEMabvtRt2Bf6PiDwuIvdly7ao6ons55PAlsWeaBVhjOkP7c4u+2ZVPSYim4EfishzC+9UVRWRRYuoq+r9wP0At/6TwAqtG7NG2tqzq+qx7Ptp4DukU0ifEpFtANn3071qpDGmc+3UequKyOC5n4F/ATwNfJ+0EgxYRRhj+l473fgtwHfSKs34wP9W1R+IyGPAN0Xkw8ArwPt610xjTKcuG/as8sutiyw/C7y1F40yxnSfXUFnTE5Y2I3JCQu7MTlhYTcmJyzsxuSEhd2YnLCwG5MTFnZjcsLCbkxOWNiNyQkLuzE5YWE3Jics7MbkhIXdmJywsBuTExZ2Y3LCwm5MTrQVdhEZEZGHROQ5ETkoIneLyKiI/FBEXsi+b+h1Y40xV67dPfvngB+o6k2kU1QdxCrCGLOutDO77DDwz4EvA6hqS1WnsIowxqwr7ezZrwPGga+KyJMi8qVsSmmrCGPMOtJO2H3gDuALqno7UOOiLruqKmmJqEuo6v2qeqeq3jk2auOBxqyVdtJ3FDiqqvuz2w+Rht8qwhizjlw27Kp6EnhVRG7MFr0VeBarCGPMutJuYcc/Ar4mIgXgMPAHpP8orCKMMetEW2FX1aeAOxe5yyrCGLNO2IiZMTlhYTcmJyzsxuSEhd2YnLCwG5MTFnZjcsLCbkxOWNiNyQkLuzE5YWE3Jics7MbkhIXdmJywsBuTExZ2Y3LCwm5MTljYjcmJdqaSvlFEnlrwNSMiH7UiEcasL+3MQfe8qt6mqrcBbwDqwHewIhHGrCsr7ca/FXhRVV/BikQYs66sNOzvB76e/dxWkQhjTH9oO+zZzLLvBr518X3LFYmwijDG9IeV7NnfATyhqqey220VibCKMMb0h5Wk7wOc78KDFYkwZl1ptz57FXgb8O0Fi/8ceJuIvAD8VnbbGNOn2i0SUQPGLlp2FisSYcy6YQfRxuSEhd2YnLCwG5MTFnZjcsLCbkxOWNiNyYm2Tr11SwLUF72o9rxaUkQSAQXRxR8svg/icMODMLYBfK/7jT1HFZlvojOzEEYk8w00bPVue8ZkVDXNgIKEwsl4mJJEyz4nRJa8b1XDHuGYSgrLPmY2KSNxFvTFwi6Shj0IYPMYszduIC4u/QK7oTQRUXq1gMw3kbOTFnazelSRWHEt4Vh4+SkjWnpmyftWNewKhLr8XjhUb4mP1CzgeYjnSMoBjRFHVO5d2EUVF3kUSgVcouk/GmNWS7bTE4W5uMSMKy378FiXPjJf3T27epyMh5d9zHg0hIsE4mzPnlz0STlxSKmIlErUrh3gzF0x3mDYw1ZD7XAJSQYoTJUo1RswOdnT7RkDQJIgUYKLEry68MzcNs4UB5Z9ynzy/JL3rWrYY3XMxMv/Z5qNS1k3nvQg/yLiBAkCKATMb3Bs332K64YmetNgIFHhp609NF4qgPoUi0HPtmXMBVQhTgPvteBMY4BkmT03LN9zXnd9Uk0UbbYQEaqnY159fjPHB0Z7us3yywUq4xGFmRBp2PG6WZ/WXdjRhKReR5pNBp45ze75MZJCb88gFqZqBCemoBWSTE33dFvG9MrqduNxTMfVZR8zGVWQSCBJTztcMlanCnGc7uFna5ROFNGgh6feAKk10Lk6hC201dvxAWMuoAqx4kKYbpZIdPnB6DDpkwG6U7UhPnNg+U/FasNj02HFn6oj9QZJdOl5RY3Tg3qt1ZDT4Lze7tk1DNH5BhrH6baNWQXaaiFnJ/FmArbsD5ia3ML4ZRIbTSx9antVw+7VhOGfLT9A50Jl+OUGMjWLtlqwWLhUQWOSeh3q9R611pi1pVFEfDYdfHanTjP6qEPc8nv2F6PakvetathdBJXx5SedlFjxZlpoGEIYocnlTrobkwPZDk4vN2frMnFpK+wi8sfAv8lW9UvgD4BtwIOkM9g8DnxIVZcdqvbmWoz845HlN5YkaK2eXpYax5BYt9mYbrhs2EVkB/AfgJtVdV5Evkk6f/w7gc+o6oMi8kXgw8AXlluXhiHRseNdaLYxZqXaHdnygbKI+EAFOAHcCzyU3W8VYYzpc+3UejsG/DfgCGnIp0m77VOqem6o/Ciwo1eNNMZ0rp0qrhtI67pdB2wHqsDb293AwoowIc0rbqgxpjPtdON/C3hJVcdVNSSdO/4eYCTr1gPsBI4t9uSFFWECil1ptDFm5doJ+xHgTSJSEREhnSv+WeBHwHuzx1hFGGP6XDvH7PtJB+KeID3t5oD7gT8FPiYih0hPv325h+00xnRIdImpn3phSEb1LrEiMsb0yn59hBmdWPQyO5tw0picsLAbkxMWdmNywsJuTE6s6gCdiIwDNWDp+W7Xn43Y6+lXV9NrgfZez7WqummxO1Y17AAickBV71zVjfaQvZ7+dTW9Fuj89Vg33picsLAbkxNrEfb712CbvWSvp39dTa8FOnw9q37MboxZG9aNNyYnVjXsIvJ2EXleRA6JyCdWc9udEpFdIvIjEXlWRJ4RkY9ky0dF5Ici8kL2/fKlNvuIiHgi8qSIPJzdvk5E9mfv0TdEZPmyu31EREZE5CEReU5EDorI3ev5/RGRP87+1p4Wka+LSKmT92fVwi4iHvB54B3AzcAHROTm1dp+F0TAn6jqzcCbgD/M2v8J4BFV3Qc8kt1eTz4CHFxw+9OkcwvuBSZJ5xZcLz4H/EBVbwJuJX1d6/L9WTD3452q+nrAI5378crfH1VdlS/gbuBvF9z+JPDJ1dp+D17P94C3Ac8D27Jl24Dn17ptK3gNO0kDcC/wMCCkF234i71n/fwFDAMvkY1DLVi+Lt8f0mneXgVGSeeAfBj47U7en9Xsxp9r/Dnrdt46EdkN3A7sB7ao6onsrpPAlrVq1xX4LPBxztfLHWP9zi14HTAOfDU7LPmSiFRZp++P9mDuRxugWyERGQD+Evioqs4svE/Tf7fr4vSGiLwLOK2qj691W7rEB+4AvqCqt5Neln1Bl32dvT8dzf24mNUM+zFg14LbS85b169EJCAN+tdU9dvZ4lMisi27fxtweq3at0L3AO8WkZdJi33cS3rM29bcgn3oKHBU05mVIJ1d6Q7W7/vT0dyPi1nNsD8G7MtGEwukgw3fX8XtdySbf+/LwEFV/YsFd32fdA4+WEdz8anqJ1V1p6ruJn0v/l5VP8g6nVtQVU8Cr4rIjdmic3Mlrsv3h17M/bjKgw7vBH4FvAj8p7UeBFlh299M2gX8BfBU9vVO0uPcR4AXgL8DRte6rVfw2t4CPJz9vAf4GXAI+BZQXOv2reB13AYcyN6j7wIb1vP7A3wKeA54GvhfQLGT98euoDMmJ2yAzpicsLAbkxMWdmNywsJuTE5Y2I3JCQu7MTlhYTcmJyzsxuTE/wdh5xBYTBxifgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "npobs=np.array(obs)\n",
    "for i in range(4):\n",
    "    plt.imshow(npobs[:,:,i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d3164",
   "metadata": {},
   "source": [
    "You can see the four consecutive frames, and the paddle has moved to the right at the bottom of the frames. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daa4284",
   "metadata": {},
   "source": [
    "## 2. Train the Agent with A Double Deep Q Network\n",
    "We'll train the agent to play the Atari Breakout game with a double deep Q network in this section.\n",
    "\n",
    "### 2.1. Create A Double Deep Q Network\n",
    "Deep Q learning has a well-known problem of overestimating the Q values. To overcome this, we use double Q learning: we'll use one deep Q network for training and another deep Q network for predicting, and periodically updated the target network from the training network. \n",
    "\n",
    "The deep Q network we use has convolutional layers since the inputs are two-dimensional pictures. We can use convolutional layers to extract features from the graphs and associate them with game strategies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d2bf6b",
   "metadata": {},
   "source": [
    "### 2.2. Train the Agent\n",
    "The script below trains the agent to play the Breakout game. It is largely based on the example script by Jacob Chapman and Mathias Lechner https://keras.io/examples/rl/deep_q_network_breakout/. I made some minor changes to shorten the script, such as using the *deque()* method from the ***collections*** library so that we don't have to keep track of the size of the memory buffer or the size of the running rewards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ee5e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 84, 84, 4)]       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 20, 20, 32)        8224      \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 9, 9, 64)          32832     \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,686,180\n",
      "Trainable params: 1,686,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "running reward: 3.86 at episode 15, frame count 10000\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "running reward: 4.00 at episode 30, frame count 20000\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "running reward: 3.95 at episode 44, frame count 30000\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "running reward: 4.05 at episode 58, frame count 40000\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "running reward: 3.97 at episode 75, frame count 50000\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "running reward: 4.09 at episode 88, frame count 60000\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "running reward: 4.16 at episode 100, frame count 70000\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "running reward: 4.24 at episode 116, frame count 80000\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "running reward: 4.25 at episode 131, frame count 90000\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from baselines.common.atari_wrappers import make_atari\n",
    "from baselines.common.atari_wrappers import wrap_deepmind\n",
    "\n",
    "# Use the Baseline Atari environment\n",
    "env = make_atari(\"BeamRiderNoFrameskip-v4\")\n",
    "# Process and stack the frames\n",
    "env = wrap_deepmind(env, frame_stack=True, scale=True)\n",
    "\n",
    "# Discount factor for past rewards\n",
    "gamma = 0.99 \n",
    "# batch size\n",
    "batch_size = 32  \n",
    "\n",
    "# The number of actions in breakout is 4\n",
    "num_actions = 4\n",
    "\n",
    "# The same double Q deep neural network, applies to all Atari games\n",
    "def create_model():\n",
    "    # Network defined by the Deepmind paper\n",
    "    inputs = layers.Input(shape=(84, 84, 4,))\n",
    "    # Convolutions on the frames on the screen\n",
    "    layer1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")(inputs)\n",
    "    layer2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")(layer1)\n",
    "    layer3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")(layer2)\n",
    "    layer4 = layers.Flatten()(layer3)\n",
    "    layer5 = layers.Dense(512, activation=\"relu\")(layer4)\n",
    "    action = layers.Dense(num_actions, activation=\"linear\")(layer5)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=action)\n",
    "\n",
    "# Double Deep Q Learning here\n",
    "# The model predicts Q-values, to determine action \n",
    "dnn=create_model()\n",
    "# Target model predicts future rewards\n",
    "# The weights of a target model are updated every 10000 frames thus when the\n",
    "# loss between the Q-values is calculated the target Q-value is stable.\n",
    "target_dnn=create_model()\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
    "loss_function = tf.keras.losses.Huber()\n",
    "\n",
    "# See how many trainable parameters in the deep neural network\n",
    "print(dnn.summary())\n",
    "\n",
    "# Create a replay buffer with a maximum length of 50000\n",
    "# If you don't have enough memory on your computer, change it to 20000\n",
    "memory=deque(maxlen=50000)\n",
    "# Create a running rewards list with a length of 100\n",
    "running_rewards=deque(maxlen=100)\n",
    "\n",
    "# Replay and update model parameters\n",
    "def replay():\n",
    "    # select a batch from the buffer memory\n",
    "    samples = random.sample(memory,batch_size)\n",
    "    dones = []\n",
    "    frames = []\n",
    "    new_frames = []\n",
    "    rewards = []\n",
    "    actions = []\n",
    "    for sample in samples:\n",
    "        frame, new_frame, action, reward, done = sample\n",
    "        frames.append(frame)\n",
    "        new_frames.append(new_frame)\n",
    "        actions.append(action)\n",
    "        dones.append(done)\n",
    "        rewards.append(reward)\n",
    "    frames=np.array(frames)\n",
    "    new_frames=np.array(new_frames)\n",
    "    dones=tf.convert_to_tensor(dones)\n",
    "\n",
    "    # update the Q table\n",
    "    preds = target_dnn.predict(new_frames, verbose=0)\n",
    "    Qs = rewards + gamma * tf.reduce_max(preds, axis=1)\n",
    "    # Each time the agent loses a life, set Q to -1; important\n",
    "    new_Qs = Qs * (1 - dones) - dones\n",
    "\n",
    "    # update model parameters\n",
    "    onehot = tf.one_hot(actions, num_actions)\n",
    "    with tf.GradientTape() as t:\n",
    "        Q_preds = dnn(frames)\n",
    "        # Calculate old Qs for the action taken\n",
    "        old_Qs = tf.reduce_sum(tf.multiply(Q_preds, onehot),axis=1)\n",
    "        # Calculate loss between new Qs and old Qs\n",
    "        loss = loss_function(new_Qs, old_Qs)\n",
    "    # Update using backpropagation\n",
    "    gs = t.gradient(loss,dnn.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gs,dnn.trainable_variables))\n",
    "    \n",
    "# Let the game begin\n",
    "running_reward = 0\n",
    "frame_count = 0\n",
    "# Number of frames to take random action and observe output\n",
    "epsilon_random_frames = 50000\n",
    "\n",
    "# Train the model after 4 actions\n",
    "update_after_actions = 4\n",
    "# How often to update the target network\n",
    "update_target_network = 10000\n",
    "\n",
    "for episode in range(1, 100000): \n",
    "    # reset state and episode reward before each episode\n",
    "    state = np.array(env.reset())\n",
    "    episode_reward = 0\n",
    "    \n",
    "    # Allow 10,000 steps per episode\n",
    "    for timestep in range(1, 10001):\n",
    "        frame_count += 1\n",
    "        # Calculate current epsilon based on frame count\n",
    "        epsilon = max(0.1, 1 - frame_count * (1-0.1) /1000000)\n",
    "        # Use epsilon-greedy for exploration\n",
    "        if frame_count < epsilon_random_frames or epsilon > np.random.rand(1)[0]:\n",
    "            # Take random action\n",
    "            action = np.random.choice(num_actions)\n",
    "        # Use exploitation\n",
    "        else:\n",
    "            # Predict action Q-values\n",
    "            # From environment state\n",
    "            state_tensor = tf.convert_to_tensor(state)\n",
    "            state_tensor = tf.expand_dims(state_tensor, 0)\n",
    "            action_probs = dnn(state_tensor, training=False)\n",
    "            # Take best action\n",
    "            action = tf.argmax(action_probs[0]).numpy()\n",
    "\n",
    "        # Apply the sampled action in our environment\n",
    "        state_next, reward, done, _ = env.step(action)\n",
    "        state_next = np.array(state_next)\n",
    "        episode_reward += reward\n",
    "        # Change done from True/False to 1.0 or 0.0 to prevent error\n",
    "        if done==True:\n",
    "            done=1.0\n",
    "        else:\n",
    "            done=0.0\n",
    "        # Save actions and states in replay buffer\n",
    "        memory.append([state, state_next, action, reward, done])\n",
    "        # current state becomes the next state in next round\n",
    "        state = state_next\n",
    "\n",
    "        # Update every fourth frame and once batch size is over 32\n",
    "        if frame_count % update_after_actions == 0 and len(memory) > batch_size:\n",
    "            replay()\n",
    "\n",
    "        if frame_count % update_target_network == 0:\n",
    "            # update the the target network with new weights\n",
    "            target_dnn.set_weights(dnn.get_weights())\n",
    "            running_reward = np.mean(np.array(running_rewards))\n",
    "            # Log details\n",
    "            template = \"running reward: {:.2f} at episode {}, frame count {}\"\n",
    "            print(template.format(running_reward, episode, frame_count))\n",
    "            # Periodically save the model\n",
    "            dnn.save(\"files/ch18/DoubleQ_Breakout.h5\")\n",
    "        if done==1.0:\n",
    "            running_rewards.append(episode_reward)\n",
    "            break\n",
    "    # Condition to consider the task solved\n",
    "    if running_reward > 40:  \n",
    "        print(f\"Solved at episode {episode}!\")\n",
    "        # save the final model\n",
    "        dnn.save(\"files/ch18/DoubleQ_Breakout_final.h5\")        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a68bf5",
   "metadata": {},
   "source": [
    "The number of trainable parameters is 1,686,180. The model takes several days to train. But you can use a trained model saved as files/ch18/breakout.h5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2558834a",
   "metadata": {},
   "source": [
    "## 3. Test the Trained Model\n",
    "Next, you'll first play five episodes of the game using the pre-trained model, so that you can visualize the pre-trained model in action. \n",
    "\n",
    "After that, you'll play the game 100 episodes and see what is the average score, without the graphical rendering of the game frames. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f042ac6e",
   "metadata": {},
   "source": [
    "### 3.1. Testing One Original Episode\n",
    "The original Atari Breakout game has 5 lives. But the baseline package breaks it down to five smaller episodes. \n",
    "\n",
    "Here you'll play the game five consecutive episodes with the baseline package so that you'll have one full original episode. \n",
    "\n",
    "You'll turn on the graphical rendering of the game frames so that you can visualize the game in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "619c3cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from baselines.common.atari_wrappers import make_atari, wrap_deepmind\n",
    "import tensorflow as tf\n",
    "\n",
    "reload = tf.keras.models.load_model(\"files/ch18/breakout.h5\")\n",
    "\n",
    "# Use the Baseline Atari environment\n",
    "env = make_atari(\"BreakoutNoFrameskip-v4\")\n",
    "# Process and stack the frames\n",
    "env = wrap_deepmind(env, frame_stack=True, scale=True)\n",
    "\n",
    "for i in range(5):\n",
    "    state = env.reset()\n",
    "    for j in range(10000):\n",
    "        if np.random.rand(1)[0]<0.01:\n",
    "            action = np.random.choice(4)\n",
    "        else:\n",
    "            state_tensor = tf.convert_to_tensor(state)\n",
    "            state_tensor = tf.expand_dims(state_tensor, 0)\n",
    "            action_probs = reload(state_tensor, training=False)\n",
    "            # Take the best action\n",
    "            action = tf.argmax(action_probs[0]).numpy()    \n",
    "        obs, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        state=obs\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70243134",
   "metadata": {},
   "source": [
    "The trained model is able to remove most, if not all bricks in the game. \n",
    "\n",
    "More important, the agent sends the ball to the back of the wall multiple times once there is at least one opening to the back of the wall. The agent has definitely \"learned\" that it's more efficient to earn points that way than directly aiming at the bricks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3058e09d",
   "metadata": {},
   "source": [
    "### 3.2. Play Multiple Games and Test the Average Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2514ab27",
   "metadata": {},
   "source": [
    "We now play 100 games and turn off the graphical rendering. We'll see what is the average score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a2649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from baselines.common.atari_wrappers import make_atari, wrap_deepmind\n",
    "import tensorflow as tf\n",
    "\n",
    "reload = tf.keras.models.load_model(\"files/ch18/breakout.h5\")\n",
    "\n",
    "# Use the Baseline Atari environment\n",
    "env = make_atari(\"BreakoutNoFrameskip-v4\")\n",
    "# Process and stack the frames\n",
    "env = wrap_deepmind(env, frame_stack=True, scale=True)\n",
    "scores = []\n",
    "for i in range(100):\n",
    "    state = env.reset()\n",
    "    score = 0\n",
    "    for j in range(10000):\n",
    "        if np.random.rand(1)[0]<0.01:\n",
    "            action = np.random.choice(4)\n",
    "        else:\n",
    "            state_tensor = tf.convert_to_tensor(state)\n",
    "            state_tensor = tf.expand_dims(state_tensor, 0)\n",
    "            action_probs = reload(state_tensor, training=False)\n",
    "            # Take the best action\n",
    "            action = tf.argmax(action_probs[0]).numpy()    \n",
    "        obs, reward, done, info = env.step(action)\n",
    "        #env.render()\n",
    "        state=obs\n",
    "        score += reward\n",
    "        if done:\n",
    "            print(f\"the score in episode {i+1} is {score}\")\n",
    "            scores.append(score)\n",
    "            break\n",
    "env.close()\n",
    "\n",
    "print(f\"the average score is {np.array(scores).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4b7b39",
   "metadata": {},
   "source": [
    "The average score is about 20 per episode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afdb60c",
   "metadata": {},
   "source": [
    "## 4. Animate Successful Episodes\n",
    "We'll highlight episode where the agent purposefully sends the ball to the back of the wall multiple times. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec2649d",
   "metadata": {},
   "source": [
    "### 4.1. Collect Successful Episodes\n",
    "We'll first record 25 episodes, and this is equivalent to five full original Atari Breakout game. \n",
    "\n",
    "The script below accomplishes that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c60f2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "frames = []\n",
    "for i in range(25):\n",
    "    state = env.reset()\n",
    "    episode_frames = []\n",
    "    for j in range(10000):\n",
    "        if np.random.rand(1)[0]<0.01:\n",
    "            action = np.random.choice(4)\n",
    "        else:\n",
    "            state_tensor = tf.convert_to_tensor(state)\n",
    "            state_tensor = tf.expand_dims(state_tensor, 0)\n",
    "            action_probs = reload(state_tensor, training=False)\n",
    "            # Take the best action\n",
    "            action = tf.argmax(action_probs[0]).numpy()    \n",
    "        obs, reward, done, info = env.step(action)\n",
    "        #env.render()\n",
    "        state=obs\n",
    "        episode_frames.append(env.render(mode='rgb_array'))\n",
    "        if done:\n",
    "            frames.append(episode_frames)\n",
    "            imageio.mimsave(f\"files/ch18/breakout_episode{i+1}.gif\", episode_frames, fps=240)\n",
    "            break\n",
    "env.close()\n",
    "\n",
    "import pickle \n",
    "pickle.dump(frames, open(f'files/ch18/breakout_frames.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd1fd1b",
   "metadata": {},
   "source": [
    "You'll see 25 short animations in your local folder. If you view them as extra large icons, you can easily tell in which ones the agent sends the ball to the back of the wall multiple times. The bricks remaining are visible from the thumbnail pictures of the animations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d6f6e2",
   "metadata": {},
   "source": [
    "### 4.2. Zoom in on Certain Steps\n",
    "Next, we'll zoom in on the steps of the game when the agent sends the ball to the back of the wall multiple times. \n",
    "For example, I will zoom in episodes 56 and 67 (the episodes for you will likely be different).\n",
    "\n",
    "Next, you'll break down episode 56 into individual pictures so that you know which frame to start and which one to stop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec0f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.makedirs(\"files/ch18/photos\", exist_ok=True)\n",
    "for i in range(len(frames[55])):\n",
    "    plt.imshow(frames[55][i])\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"files/ch18/photos/photo{i+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e0aabe",
   "metadata": {},
   "source": [
    "By browsing through the pictures, it seems that the agent has sent the ball to the back of the wall from photos numbered 100 to 294. We therefore keep only those frames, like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8f7fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimsave(\"files/ch18/breakout_highlight.gif\", frames[55][100:294], fps=240)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2b5e83",
   "metadata": {},
   "source": [
    "In the animation below, you can see that the agent has sent the ball to the back of the wall five consecutive times. It's clear that the agent has \"learned\" to do this on purpose because this is a more efficient way of earning rewards than aiming at the bricks directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5608690c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://gattonweb.uky.edu/faculty/lium/ml/breakout_highlight.gif\" />\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML \n",
    "<img src=\"https://gattonweb.uky.edu/faculty/lium/ml/breakout_highlight.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feed635",
   "metadata": {},
   "source": [
    "Similarly, we can break down episode 67 into individual pictures so that you know which frame to start and which one to stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"files/ch18/photos2\", exist_ok=True)\n",
    "for i in range(len(frames[66])):\n",
    "    plt.imshow(frames[66][i])\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"files/ch18/photos2/photo{i+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e462860d",
   "metadata": {},
   "source": [
    "By browsing through the pictures, it seems that the agent has sent the ball to the back of the wall from photos numbered 140 to 289. We therefore keep only those frames, like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0332bc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimsave(\"files/ch18/breakout_highlight2.gif\", frames[66][140:289], fps=240)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54583cf2",
   "metadata": {},
   "source": [
    "The animation looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7c1718a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://gattonweb.uky.edu/faculty/lium/ml/breakout_highlight2.gif\" />\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML \n",
    "<img src=\"https://gattonweb.uky.edu/faculty/lium/ml/breakout_highlight2.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2023e7e1",
   "metadata": {},
   "source": [
    "### 4.3. Combine the Highlights\n",
    "We'll combine the two highlights into one animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8821b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames1 = frames[55][100:294]\n",
    "frames2 = frames[66][140:289]\n",
    "frames2 = frames2 + frames2\n",
    "fs = []\n",
    "for i in range(min(len(frames1), len(frames2))):\n",
    "    if i%2==0:\n",
    "        f1 = frames1[i]\n",
    "        f2 = frames2[i]\n",
    "        middle = np.full(f1.shape, 255).astype(\"uint8\")\n",
    "        f12 = np.concatenate([f1, middle, f2], axis=1)\n",
    "        fs.append(f12)\n",
    "imageio.mimsave('files/ch18/breakout_highlights.gif', fs, fps=600) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c728bb",
   "metadata": {},
   "source": [
    "The animation looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "731b2efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://gattonweb.uky.edu/faculty/lium/ml/breakout_highlights.gif\" />\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<img src=\"https://gattonweb.uky.edu/faculty/lium/ml/breakout_highlights.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3f1b87",
   "metadata": {},
   "source": [
    "The animation shows that the agent can \"learn\" to score more efficiently by just interacting with the game environment. This is the essence of reinforcement learning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
